{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data mining project - 2020/21</b><br>\n",
    "<b>Author</b>: [Alexandra Bradan](https://github.com/alexandrabradan)<br>\n",
    "<b>Python version</b>: 3.x<br>\n",
    "<b>Last update: 07/01/2021<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# general libraries\n",
    "import sys\n",
    "import math\n",
    "import operator\n",
    "import itertools\n",
    "import pydotplus\n",
    "import collections\n",
    "import missingno as msno\n",
    "from pylab import MaxNLocator\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "from collections import defaultdict\n",
    "from IPython.display import Image\n",
    "\n",
    "# pandas libraries\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "# visualisation libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "# numpy libraries\n",
    "import numpy as np\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "from numpy import arange\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from numpy import percentile\n",
    "\n",
    "# scipy libraries\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.experimental import enable_iterative_imputer  # explicitly require this experimental feature\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.pipeline import make_pipeline as imbmake_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score, recall_score, precision_score, classification_report, roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fim import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../../../data/\"\n",
    "TR_impunted_file = data_directory + \"Impunted_Train_HR_Employee_Attrition.csv\"\n",
    "TS_impunted_file = data_directory + \"Impunted_Test_HR_Employee_Attrition.csv\"\n",
    "TR_not_impunted = data_directory + \"Not_Impunted_Train_HR_Employee_Attrition.csv\"\n",
    "TS_not_impunted = data_directory + \"Cleaned_Test_HR_Employee_Attrition.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Impunted TR Dataframe</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(883, 30)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_impunted = pd.read_csv(TR_impunted_file, sep=\",\") \n",
    "df_impunted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(883, 24)\n"
     ]
    }
   ],
   "source": [
    "to_drop = [\"MaritalStatus\", \"EducationField\", \"Department\", \"YearsSinceLastPromotion\", \"HourlyRate\", \"MonthlyRate\"]\n",
    "\n",
    "# drop features \n",
    "for column_name in to_drop:\n",
    "    del df_impunted[column_name]\n",
    "    \n",
    "# check dropping output\n",
    "print(df_impunted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 883 entries, 0 to 882\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       883 non-null    int64  \n",
      " 1   Attrition                 883 non-null    object \n",
      " 2   BusinessTravel            883 non-null    object \n",
      " 3   DistanceFromHome          883 non-null    int64  \n",
      " 4   Education                 883 non-null    int64  \n",
      " 5   EnvironmentSatisfaction   883 non-null    int64  \n",
      " 6   Gender                    883 non-null    object \n",
      " 7   JobInvolvement            883 non-null    int64  \n",
      " 8   JobLevel                  883 non-null    int64  \n",
      " 9   JobRole                   883 non-null    object \n",
      " 10  JobSatisfaction           883 non-null    int64  \n",
      " 11  MonthlyIncome             883 non-null    int64  \n",
      " 12  NumCompaniesWorked        883 non-null    int64  \n",
      " 13  OverTime                  883 non-null    object \n",
      " 14  PercentSalaryHike         883 non-null    int64  \n",
      " 15  RelationshipSatisfaction  883 non-null    int64  \n",
      " 16  StockOptionLevel          883 non-null    int64  \n",
      " 17  TrainingTimesLastYear     883 non-null    int64  \n",
      " 18  WorkLifeBalance           883 non-null    int64  \n",
      " 19  YearsAtCompany            883 non-null    int64  \n",
      " 20  YearsInCurrentRole        883 non-null    int64  \n",
      " 21  MonthlyHours              883 non-null    float64\n",
      " 22  TaxRate                   883 non-null    float64\n",
      " 23  OverallSatisfaction       883 non-null    float64\n",
      "dtypes: float64(3), int64(16), object(5)\n",
      "memory usage: 165.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_impunted.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Not-impunted TR DataFrame</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(883, 30)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_impunted = pd.read_csv(TR_not_impunted, sep=\",\") \n",
    "df_not_impunted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(883, 24)\n"
     ]
    }
   ],
   "source": [
    "to_drop = [\"MaritalStatus\", \"EducationField\", \"Department\", \"YearsSinceLastPromotion\", \"HourlyRate\", \"MonthlyRate\"]\n",
    "\n",
    "# drop features \n",
    "for column_name in to_drop:\n",
    "    del df_not_impunted[column_name]\n",
    "    \n",
    "# check dropping output\n",
    "print(df_not_impunted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Impunted TS DataFrame </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 24)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts = pd.read_csv(TS_impunted_file, sep=\",\") \n",
    "df_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219 entries, 0 to 218\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       219 non-null    int64  \n",
      " 1   Attrition                 219 non-null    object \n",
      " 2   BusinessTravel            219 non-null    object \n",
      " 3   DistanceFromHome          219 non-null    int64  \n",
      " 4   Education                 219 non-null    int64  \n",
      " 5   EnvironmentSatisfaction   219 non-null    int64  \n",
      " 6   Gender                    219 non-null    object \n",
      " 7   JobInvolvement            219 non-null    int64  \n",
      " 8   JobLevel                  219 non-null    int64  \n",
      " 9   JobRole                   219 non-null    object \n",
      " 10  JobSatisfaction           219 non-null    int64  \n",
      " 11  MonthlyIncome             219 non-null    int64  \n",
      " 12  NumCompaniesWorked        219 non-null    int64  \n",
      " 13  OverTime                  219 non-null    object \n",
      " 14  PercentSalaryHike         219 non-null    int64  \n",
      " 15  RelationshipSatisfaction  219 non-null    int64  \n",
      " 16  StockOptionLevel          219 non-null    int64  \n",
      " 17  TrainingTimesLastYear     219 non-null    int64  \n",
      " 18  WorkLifeBalance           219 non-null    int64  \n",
      " 19  YearsAtCompany            219 non-null    int64  \n",
      " 20  YearsInCurrentRole        219 non-null    int64  \n",
      " 21  MonthlyHours              219 non-null    float64\n",
      " 22  TaxRate                   219 non-null    float64\n",
      " 23  OverallSatisfaction       219 non-null    float64\n",
      "dtypes: float64(3), int64(16), object(5)\n",
      "memory usage: 41.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Not-impnted TS DataFrame </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped rows = \t8\n",
      "dropped rows = \t2\n",
      "dropped rows = \t7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(219, 24)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_not_impunted = pd.read_csv(TS_not_impunted, sep=\",\") \n",
    "df_ts_not_impunted.shape\n",
    "\n",
    "del df_ts_not_impunted[\"Department\"]\n",
    "del df_ts_not_impunted[\"MonthlyRate\"]\n",
    "\n",
    "\n",
    "to_drop_indexes = df_ts_not_impunted.index[df_ts_not_impunted[\"YearsAtCompany\"] > 20]\n",
    "df_ts_not_impunted.drop(list(to_drop_indexes), axis=0, inplace=True)\n",
    "df_ts_not_impunted.reset_index(drop=True, inplace=True)\n",
    "print(\"dropped rows = \", len(to_drop_indexes), sep=\"\\t\")\n",
    "\n",
    "to_drop_indexes = df_ts_not_impunted.index[df_ts_not_impunted[\"YearsInCurrentRole\"] > 16]\n",
    "df_ts_not_impunted.drop(list(to_drop_indexes), axis=0, inplace=True)\n",
    "df_ts_not_impunted.reset_index(drop=True, inplace=True)\n",
    "print(\"dropped rows = \", len(to_drop_indexes), sep=\"\\t\")\n",
    "\n",
    "to_drop_indexes = df_ts_not_impunted.index[df_ts_not_impunted[\"MonthlyHours\"] > 590.9767441860465]\n",
    "df_ts_not_impunted.drop(list(to_drop_indexes), axis=0, inplace=True)\n",
    "df_ts_not_impunted.reset_index(drop=True, inplace=True)\n",
    "print(\"dropped rows = \", len(to_drop_indexes), sep=\"\\t\")\n",
    "\n",
    "df_ts_not_impunted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219 entries, 0 to 218\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       191 non-null    float64\n",
      " 1   Attrition                 219 non-null    object \n",
      " 2   BusinessTravel            202 non-null    object \n",
      " 3   DistanceFromHome          219 non-null    int64  \n",
      " 4   Education                 219 non-null    int64  \n",
      " 5   EnvironmentSatisfaction   219 non-null    int64  \n",
      " 6   Gender                    208 non-null    object \n",
      " 7   JobInvolvement            219 non-null    int64  \n",
      " 8   JobLevel                  219 non-null    int64  \n",
      " 9   JobRole                   219 non-null    object \n",
      " 10  JobSatisfaction           219 non-null    int64  \n",
      " 11  MonthlyIncome             168 non-null    float64\n",
      " 12  NumCompaniesWorked        219 non-null    int64  \n",
      " 13  OverTime                  219 non-null    object \n",
      " 14  PercentSalaryHike         219 non-null    int64  \n",
      " 15  RelationshipSatisfaction  219 non-null    int64  \n",
      " 16  StockOptionLevel          219 non-null    int64  \n",
      " 17  TrainingTimesLastYear     170 non-null    float64\n",
      " 18  WorkLifeBalance           219 non-null    int64  \n",
      " 19  YearsAtCompany            207 non-null    float64\n",
      " 20  YearsInCurrentRole        219 non-null    int64  \n",
      " 21  MonthlyHours              219 non-null    float64\n",
      " 22  TaxRate                   168 non-null    float64\n",
      " 23  OverallSatisfaction       219 non-null    float64\n",
      "dtypes: float64(7), int64(12), object(5)\n",
      "memory usage: 41.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ts_not_impunted.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Continuos variables discretisation with K-Means</h2>\n",
    "K-Means => similar bins' size => IBM's Age and opportunity equity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_converted = df_impunted.copy()\n",
    "df_ts_conv = df_ts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_performed_encoding(column_name, train_encoded):\n",
    "    column_index = df_impunted.columns.get_loc(column_name)\n",
    "    encoding_info = {}\n",
    "    for enc, i in zip(train_encoded, range(0, len(train_encoded))):\n",
    "        try:\n",
    "            tmp_list = encoding_info[str(enc)]\n",
    "            tmp_list.append(df_impunted.iloc[i, column_index])\n",
    "            encoding_info[str(enc)] = tmp_list\n",
    "        except KeyError:\n",
    "            encoding_info[str(enc)] = [df_impunted.iloc[i, column_index]]\n",
    "            \n",
    "    for key, value in encoding_info.items():\n",
    "        min_value = min(value)\n",
    "        max_value = max(value)\n",
    "        print(column_name, key, \"[%s-%s]\" %(min_value, max_value),sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\t[3]\t[48-60]\n",
      "Age\t[1]\t[31-38]\n",
      "Age\t[0]\t[18-30]\n",
      "Age\t[2]\t[39-47]\n",
      "DistanceFromHome\t[1]\t[6-13]\n",
      "DistanceFromHome\t[0]\t[1-5]\n",
      "DistanceFromHome\t[2]\t[14-21]\n",
      "DistanceFromHome\t[3]\t[22-29]\n",
      "MonthlyIncome\t[1]\t[7094-13888]\n",
      "MonthlyIncome\t[0]\t[1009-6992]\n",
      "MonthlyIncome\t[2]\t[14004-20520]\n",
      "MonthlyIncome\t[3]\t[20933-26997]\n",
      "NumCompaniesWorked\t[3]\t[7-9]\n",
      "NumCompaniesWorked\t[0]\t[0-2]\n",
      "NumCompaniesWorked\t[1]\t[3-4]\n",
      "NumCompaniesWorked\t[2]\t[5-6]\n",
      "PercentSalaryHike\t[1]\t[15-18]\n",
      "PercentSalaryHike\t[0]\t[11-14]\n",
      "PercentSalaryHike\t[3]\t[22-25]\n",
      "PercentSalaryHike\t[2]\t[19-21]\n",
      "YearsAtCompany\t[1]\t[6-10]\n",
      "YearsAtCompany\t[0]\t[0-5]\n",
      "YearsAtCompany\t[2]\t[11-14]\n",
      "YearsAtCompany\t[3]\t[15-20]\n",
      "YearsInCurrentRole\t[1]\t[5-8]\n",
      "YearsInCurrentRole\t[0]\t[0-4]\n",
      "YearsInCurrentRole\t[2]\t[9-12]\n",
      "YearsInCurrentRole\t[3]\t[13-16]\n",
      "TaxRate\t[1]\t[0.2033107599699022-0.4878233954330433]\n",
      "TaxRate\t[2]\t[0.4902649218001915-0.7143783124261257]\n",
      "TaxRate\t[3]\t[0.7168701095461659-0.9513959334891722]\n",
      "TaxRate\t[0]\t[0.0-0.20014044943820225]\n",
      "MonthlyHours\t[1]\t[151.64893617021278-264.325]\n",
      "MonthlyHours\t[3]\t[404.2033898305085-590.9767441860465]\n",
      "MonthlyHours\t[2]\t[265.0588235294117-403.135593220339]\n",
      "MonthlyHours\t[0]\t[26.04347826086957-150.85333333333332]\n",
      "OverallSatisfaction\t[2]\t[2.6-3.0]\n",
      "OverallSatisfaction\t[3]\t[3.2-4.0]\n",
      "OverallSatisfaction\t[1]\t[2.0-2.4]\n",
      "OverallSatisfaction\t[0]\t[1.2-1.8]\n"
     ]
    }
   ],
   "source": [
    "cont_variables = [\"Age\", \"DistanceFromHome\", \"MonthlyIncome\", \"NumCompaniesWorked\", \"PercentSalaryHike\",\n",
    "                 \"YearsAtCompany\", \"YearsInCurrentRole\", \"TaxRate\", \"MonthlyHours\", \"OverallSatisfaction\"]\n",
    "\n",
    "for column_name in cont_variables:\n",
    "    discretizer = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='kmeans').fit(df_converted[[column_name]])\n",
    "    train_encoded = discretizer.transform(df_converted[[column_name]]).astype(int)\n",
    "    df_converted[column_name] = train_encoded\n",
    "    df_ts_conv[column_name] = discretizer.transform(df_ts_conv[[column_name]]).astype(int)\n",
    "    print_performed_encoding(column_name, train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in list(df_converted.columns):\n",
    "    df_converted[column_name] = df_converted[column_name].astype(str) + \"_\" + column_name\n",
    "    df_ts_conv[column_name] = df_ts_conv[column_name].astype(str) + \"_\" + column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction creation \n",
    "df_db = df_converted.values.tolist()\n",
    "df_ts_db = df_ts_conv.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Missing values TR and TS discretisation </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_impunted_converted = df_not_impunted.copy()\n",
    "df_ts_not_imp_conv = df_ts_not_impunted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_variables = [\"Age\", \"DistanceFromHome\", \"MonthlyIncome\", \"NumCompaniesWorked\", \"PercentSalaryHike\",\n",
    "                 \"YearsAtCompany\", \"YearsInCurrentRole\", \"TaxRate\", \"MonthlyHours\", \"OverallSatisfaction\"]\n",
    "\n",
    "for column_name in cont_variables:\n",
    "    discretizer = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='kmeans').fit(df_impunted[[column_name]])\n",
    "    train_encoded = discretizer.transform(df_impunted[[column_name]]).astype(int)\n",
    "    df_not_impunted_converted[column_name] = train_encoded\n",
    "    df_ts_not_imp_conv[column_name] = discretizer.transform(df_ts[[column_name]]).astype(int)\n",
    "    # print_performed_encoding(column_name, train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in list(df_converted.columns):\n",
    "    df_not_impunted_converted[column_name] = df_not_impunted_converted[column_name].astype(str) + \"_\" + column_name\n",
    "    df_ts_not_imp_conv[column_name] = df_ts_not_imp_conv[column_name].astype(str) + \"_\" + column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_numeric_values_columns = [\"Age\", \"YearsAtCompany\", \"MonthlyIncome\", \"TaxRate\", \"TrainingTimesLastYear\"]\n",
    "for column_name in missing_numeric_values_columns:\n",
    "    for i in range(0, len(df_not_impunted)):\n",
    "        column_index = df_not_impunted.columns.get_loc(column_name)\n",
    "        if df_not_impunted.iloc[i, column_index] >= 0:\n",
    "            pass\n",
    "        else:\n",
    "            df_not_impunted_converted.iloc[i, column_index] =  df_not_impunted.iloc[i, column_index]\n",
    "            \n",
    "for column_name in missing_numeric_values_columns:\n",
    "    for i in range(0, len(df_ts_not_impunted)):\n",
    "        column_index = df_ts_not_impunted.columns.get_loc(column_name)\n",
    "        if df_ts_not_impunted.iloc[i, column_index] >= 0:\n",
    "            pass\n",
    "        else:\n",
    "            df_ts_not_imp_conv.iloc[i, column_index] = df_ts_not_impunted.iloc[i, column_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_categorical_values_columns = [\"BusinessTravel\", \"Gender\"]\n",
    "for column_name in missing_categorical_values_columns:\n",
    "    for i in range(0, len(df_not_impunted)):\n",
    "        column_index = df_not_impunted.columns.get_loc(column_name)\n",
    "        if df_not_impunted.iloc[i, column_index] != \"Male\" and \\\n",
    "        df_not_impunted.iloc[i, column_index] != \"Female\" and \\\n",
    "        df_not_impunted.iloc[i, column_index] != \"Travel_Rarely\" and \\\n",
    "        df_not_impunted.iloc[i, column_index] != \"Travel_Frequently\" and \\\n",
    "        df_not_impunted.iloc[i, column_index] != \"Non-Travel\":\n",
    "            df_not_impunted_converted.iloc[i, column_index] =  df_not_impunted.iloc[i, column_index]\n",
    "            \n",
    "for column_name in missing_categorical_values_columns:\n",
    "    for i in range(0, len(df_ts_not_impunted)):\n",
    "        column_index = df_ts_not_impunted.columns.get_loc(column_name)\n",
    "        if df_ts_not_impunted.iloc[i, column_index] != \"Male\" and \\\n",
    "        df_ts_not_impunted.iloc[i, column_index] != \"Female\" and \\\n",
    "        df_ts_not_impunted.iloc[i, column_index] != \"Travel_Rarely\" and \\\n",
    "        df_ts_not_impunted.iloc[i, column_index] != \"Travel_Frequently\" and \\\n",
    "        df_ts_not_impunted.iloc[i, column_index] != \"Non-Travel\":\n",
    "            df_ts_not_imp_conv.iloc[i, column_index] = df_ts_not_impunted.iloc[i, column_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Print rules with highest confidence</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmin_range = range(2, len(df_converted.columns))  # k = 2,...,n_features \n",
    "support_range = [10]\n",
    "confidence_range = range(5, 101, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_itemsets_info = {}\n",
    "for zmin in zmin_range:\n",
    "    global_itemsets_info[str(zmin)] = {}\n",
    "    for supp in support_range:\n",
    "        global_itemsets_info[str(zmin)][str(supp)] = {}\n",
    "        for conf in confidence_range:\n",
    "            global_itemsets_info[str(zmin)][str(supp)][str(conf)] = {}\n",
    "            global_itemsets_info[str(zmin)][str(supp)][str(conf)][\"r\"] = []\n",
    "            global_itemsets_info[str(zmin)][str(supp)][str(conf)][\"l\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of r itemsets for zmin=2, supp=10: 457367\n",
      "Number of r itemsets for zmin=2, supp=10: 383132\n",
      "Number of r itemsets for zmin=2, supp=10: 322119\n",
      "Number of r itemsets for zmin=2, supp=10: 265131\n",
      "Number of r itemsets for zmin=2, supp=10: 205857\n",
      "Number of r itemsets for zmin=2, supp=10: 157517\n",
      "Number of r itemsets for zmin=2, supp=10: 117284\n",
      "Number of r itemsets for zmin=2, supp=10: 90148\n",
      "Number of r itemsets for zmin=2, supp=10: 70082\n",
      "Number of r itemsets for zmin=2, supp=10: 57355\n",
      "Number of r itemsets for zmin=2, supp=10: 46381\n",
      "Number of r itemsets for zmin=2, supp=10: 33459\n",
      "Number of r itemsets for zmin=2, supp=10: 21939\n",
      "Number of r itemsets for zmin=2, supp=10: 13740\n",
      "Number of r itemsets for zmin=2, supp=10: 7712\n",
      "Number of r itemsets for zmin=2, supp=10: 3993\n",
      "Number of r itemsets for zmin=2, supp=10: 2232\n",
      "Number of r itemsets for zmin=2, supp=10: 768\n",
      "Number of r itemsets for zmin=2, supp=10: 147\n",
      "Number of r itemsets for zmin=2, supp=10: 76\n",
      "\n",
      "Number of r itemsets for zmin=3, supp=10: 451117\n",
      "Number of r itemsets for zmin=3, supp=10: 377960\n",
      "Number of r itemsets for zmin=3, supp=10: 317770\n",
      "Number of r itemsets for zmin=3, supp=10: 261504\n",
      "Number of r itemsets for zmin=3, supp=10: 203057\n",
      "Number of r itemsets for zmin=3, supp=10: 155411\n",
      "Number of r itemsets for zmin=3, supp=10: 115673\n",
      "Number of r itemsets for zmin=3, supp=10: 88870\n",
      "Number of r itemsets for zmin=3, supp=10: 69058\n",
      "Number of r itemsets for zmin=3, supp=10: 56520\n",
      "Number of r itemsets for zmin=3, supp=10: 45697\n",
      "Number of r itemsets for zmin=3, supp=10: 32975\n",
      "Number of r itemsets for zmin=3, supp=10: 21597\n",
      "Number of r itemsets for zmin=3, supp=10: 13501\n",
      "Number of r itemsets for zmin=3, supp=10: 7590\n",
      "Number of r itemsets for zmin=3, supp=10: 3925\n",
      "Number of r itemsets for zmin=3, supp=10: 2208\n",
      "Number of r itemsets for zmin=3, supp=10: 761\n",
      "Number of r itemsets for zmin=3, supp=10: 146\n",
      "Number of r itemsets for zmin=3, supp=10: 76\n",
      "\n",
      "Number of r itemsets for zmin=4, supp=10: 383528\n",
      "Number of r itemsets for zmin=4, supp=10: 321736\n",
      "Number of r itemsets for zmin=4, supp=10: 270526\n",
      "Number of r itemsets for zmin=4, supp=10: 222016\n",
      "Number of r itemsets for zmin=4, supp=10: 172595\n",
      "Number of r itemsets for zmin=4, supp=10: 132112\n",
      "Number of r itemsets for zmin=4, supp=10: 98027\n",
      "Number of r itemsets for zmin=4, supp=10: 74924\n",
      "Number of r itemsets for zmin=4, supp=10: 57922\n",
      "Number of r itemsets for zmin=4, supp=10: 47325\n",
      "Number of r itemsets for zmin=4, supp=10: 38235\n",
      "Number of r itemsets for zmin=4, supp=10: 27564\n",
      "Number of r itemsets for zmin=4, supp=10: 17819\n",
      "Number of r itemsets for zmin=4, supp=10: 11035\n",
      "Number of r itemsets for zmin=4, supp=10: 6238\n",
      "Number of r itemsets for zmin=4, supp=10: 3196\n",
      "Number of r itemsets for zmin=4, supp=10: 1830\n",
      "Number of r itemsets for zmin=4, supp=10: 635\n",
      "Number of r itemsets for zmin=4, supp=10: 114\n",
      "Number of r itemsets for zmin=4, supp=10: 64\n",
      "\n",
      "Number of r itemsets for zmin=5, supp=10: 207273\n",
      "Number of r itemsets for zmin=5, supp=10: 174455\n",
      "Number of r itemsets for zmin=5, supp=10: 146483\n",
      "Number of r itemsets for zmin=5, supp=10: 119537\n",
      "Number of r itemsets for zmin=5, supp=10: 93141\n",
      "Number of r itemsets for zmin=5, supp=10: 71436\n",
      "Number of r itemsets for zmin=5, supp=10: 52738\n",
      "Number of r itemsets for zmin=5, supp=10: 39534\n",
      "Number of r itemsets for zmin=5, supp=10: 30032\n",
      "Number of r itemsets for zmin=5, supp=10: 24281\n",
      "Number of r itemsets for zmin=5, supp=10: 19632\n",
      "Number of r itemsets for zmin=5, supp=10: 13999\n",
      "Number of r itemsets for zmin=5, supp=10: 8731\n",
      "Number of r itemsets for zmin=5, supp=10: 5219\n",
      "Number of r itemsets for zmin=5, supp=10: 2944\n",
      "Number of r itemsets for zmin=5, supp=10: 1445\n",
      "Number of r itemsets for zmin=5, supp=10: 836\n",
      "Number of r itemsets for zmin=5, supp=10: 282\n",
      "Number of r itemsets for zmin=5, supp=10: 39\n",
      "Number of r itemsets for zmin=5, supp=10: 21\n",
      "\n",
      "Number of r itemsets for zmin=6, supp=10: 52306\n",
      "Number of r itemsets for zmin=6, supp=10: 44289\n",
      "Number of r itemsets for zmin=6, supp=10: 36905\n",
      "Number of r itemsets for zmin=6, supp=10: 30069\n",
      "Number of r itemsets for zmin=6, supp=10: 23509\n",
      "Number of r itemsets for zmin=6, supp=10: 18064\n",
      "Number of r itemsets for zmin=6, supp=10: 13281\n",
      "Number of r itemsets for zmin=6, supp=10: 9646\n",
      "Number of r itemsets for zmin=6, supp=10: 7059\n",
      "Number of r itemsets for zmin=6, supp=10: 5554\n",
      "Number of r itemsets for zmin=6, supp=10: 4487\n",
      "Number of r itemsets for zmin=6, supp=10: 3121\n",
      "Number of r itemsets for zmin=6, supp=10: 1748\n",
      "Number of r itemsets for zmin=6, supp=10: 942\n",
      "Number of r itemsets for zmin=6, supp=10: 534\n",
      "Number of r itemsets for zmin=6, supp=10: 244\n",
      "Number of r itemsets for zmin=6, supp=10: 148\n",
      "Number of r itemsets for zmin=6, supp=10: 45\n",
      "Number of r itemsets for zmin=6, supp=10: 0\n",
      "Number of r itemsets for zmin=6, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=7, supp=10: 4088\n",
      "Number of r itemsets for zmin=7, supp=10: 3494\n",
      "Number of r itemsets for zmin=7, supp=10: 2877\n",
      "Number of r itemsets for zmin=7, supp=10: 2351\n",
      "Number of r itemsets for zmin=7, supp=10: 1838\n",
      "Number of r itemsets for zmin=7, supp=10: 1398\n",
      "Number of r itemsets for zmin=7, supp=10: 1039\n",
      "Number of r itemsets for zmin=7, supp=10: 741\n",
      "Number of r itemsets for zmin=7, supp=10: 505\n",
      "Number of r itemsets for zmin=7, supp=10: 379\n",
      "Number of r itemsets for zmin=7, supp=10: 299\n",
      "Number of r itemsets for zmin=7, supp=10: 198\n",
      "Number of r itemsets for zmin=7, supp=10: 83\n",
      "Number of r itemsets for zmin=7, supp=10: 17\n",
      "Number of r itemsets for zmin=7, supp=10: 3\n",
      "Number of r itemsets for zmin=7, supp=10: 0\n",
      "Number of r itemsets for zmin=7, supp=10: 0\n",
      "Number of r itemsets for zmin=7, supp=10: 0\n",
      "Number of r itemsets for zmin=7, supp=10: 0\n",
      "Number of r itemsets for zmin=7, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "Number of r itemsets for zmin=8, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "Number of r itemsets for zmin=9, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "Number of r itemsets for zmin=10, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "Number of r itemsets for zmin=11, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "Number of r itemsets for zmin=12, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "Number of r itemsets for zmin=13, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "Number of r itemsets for zmin=14, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "Number of r itemsets for zmin=15, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "Number of r itemsets for zmin=16, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "Number of r itemsets for zmin=17, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "Number of r itemsets for zmin=18, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "Number of r itemsets for zmin=19, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "Number of r itemsets for zmin=20, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "Number of r itemsets for zmin=21, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "Number of r itemsets for zmin=22, supp=10: 0\n",
      "\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "Number of r itemsets for zmin=23, supp=10: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "itemset_types = ['r']\n",
    "\n",
    "for itemset_type in itemset_types:\n",
    "    for zmin in zmin_range:\n",
    "        for supp in support_range:\n",
    "            for conf in confidence_range:\n",
    "                itemsets = apriori(df_db, supp=supp, zmin=zmin, conf=conf, target=itemset_type, report='ascl')  \n",
    "                print('Number of %s itemsets for zmin=%s, supp=%s:' % (itemset_type, zmin, supp), len(itemsets))\n",
    "                # update global dict\n",
    "                for itemset in itemsets:\n",
    "                    antecedents = itemset[1]\n",
    "                    conseguent = itemset[0]\n",
    "                    lift = itemset[5]\n",
    "                    rule = antecedents + (conseguent,)  # post-pend conseguent to antecedents\n",
    "                    global_itemsets_info[str(zmin)][str(supp)][str(conf)][str(itemset_type)].append(rule)\n",
    "                    global_itemsets_info[str(zmin)][str(supp)][str(conf)][\"l\"].append(lift)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Checking how many strong AR (confidence >= 36) there are</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot # of strong AR = 275939\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "strong_ar = set()\n",
    "for zmin in zmin_range:\n",
    "    for supp in support_range:\n",
    "        for conf in confidence_range:\n",
    "            for i in range(0, len(global_itemsets_info[str(zmin)][str(supp)][str(conf)][\"r\"])):\n",
    "                rule = global_itemsets_info[str(zmin)][str(supp)][str(conf)][\"r\"][i]\n",
    "                lift = global_itemsets_info[str(zmin)][str(supp)][str(conf)][\"l\"][i]\n",
    "                if float(conf) >= 60:\n",
    "                    count += 1\n",
    "                    strong_ar.add(rule)\n",
    "print(\"tot # of strong AR = %d\" % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strong_ar_conseguents 21\n"
     ]
    }
   ],
   "source": [
    "strong_ar_conseguents = set()\n",
    "for itemset in strong_ar:\n",
    "    # keeping only ARs which contains column's missing value as conseguent\n",
    "    if \"BusinessTravel\" in str(itemset[-1]):\n",
    "        strong_ar_conseguents.add(\"BusinessTravel\")\n",
    "    else:\n",
    "        strong_ar_conseguents.add(str(itemset[-1]).split(\"_\")[1])\n",
    "print(\"strong_ar_conseguents\", len(strong_ar_conseguents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attrition',\n",
       " 'BusinessTravel',\n",
       " 'DistanceFromHome',\n",
       " 'EnvironmentSatisfaction',\n",
       " 'Gender',\n",
       " 'JobInvolvement',\n",
       " 'JobLevel',\n",
       " 'JobSatisfaction',\n",
       " 'MonthlyHours',\n",
       " 'MonthlyIncome',\n",
       " 'NumCompaniesWorked',\n",
       " 'OverTime',\n",
       " 'OverallSatisfaction',\n",
       " 'PercentSalaryHike',\n",
       " 'RelationshipSatisfaction',\n",
       " 'StockOptionLevel',\n",
       " 'TaxRate',\n",
       " 'TrainingTimesLastYear',\n",
       " 'WorkLifeBalance',\n",
       " 'YearsAtCompany',\n",
       " 'YearsInCurrentRole'}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_ar_conseguents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('all_strong_association_rules.pickle', 'wb') as handle:\n",
    "    pickle.dump(strong_ar, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Impute missing data using correlated AR</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_columns = missing_numeric_values_columns + missing_categorical_values_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Train imputation </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ARs_with_which_to_impunt(missing_column_name): \n",
    "    ar_impunters = set()\n",
    "    for itemset in strong_ar:\n",
    "        # keeping only ARs which contains column's missing value as conseguent\n",
    "        if str(missing_column_name) in str(itemset[-1]):\n",
    "            ar_impunters.add(itemset)\n",
    "    return ar_impunters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AR_impunter(df, record_indeces, missing_column_name):\n",
    "    missing_column_index = df.columns.get_loc(missing_column_name)\n",
    "    ar_impunters = get_ARs_with_which_to_impunt(missing_column_name)\n",
    "        \n",
    "    # for every itemset I'm checking if the variables of the record with missing value/s \n",
    "    # match the ones present in the itemset. If it does so and the itemset contains also \n",
    "    # variables with which to impunt record's missing value/s, I'm taking a MAJORITY VOTE\n",
    "    # among all Yes_Attrition ARs to impunte the missing value/s\n",
    "    mode_guessing = [\"\"]*len(record_indeces)\n",
    "    for record_index, ri in zip(record_indeces, range(0, len(record_indeces))):\n",
    "        tmp_mode_guessing = []\n",
    "        for itemset in ar_impunters:\n",
    "            matching_AR_flag = True\n",
    "            for i in range(0, len(itemset)):  # I'm using also Attrition this time\n",
    "                if \"BusinessTravel\" in itemset[i]:\n",
    "                    column_name = \"BusinessTravel\"\n",
    "                else:\n",
    "                    column_name = itemset[i].split(\"_\")[1]\n",
    "                column_index = df.columns.get_loc(column_name)\n",
    "                if column_index != missing_column_index:\n",
    "                    if df.iloc[record_index, column_index] != itemset[i]:\n",
    "                        matching_AR_flag = False\n",
    "                        break\n",
    "            if matching_AR_flag:\n",
    "                # replacing missing values with ARs\n",
    "                for j in range(0, len(itemset)):\n",
    "                    if \"BusinessTravel\" in itemset[j]:\n",
    "                        column_name = \"BusinessTravel\"\n",
    "                    else:\n",
    "                        column_name = itemset[j].split(\"_\")[1]\n",
    "                    column_index = df.columns.get_loc(column_name)\n",
    "                    if column_index == missing_column_index:\n",
    "                        tmp_mode_guessing.append(itemset[j])\n",
    "            if len(tmp_mode_guessing) > 0:\n",
    "                mode_guessing[ri] =  max(set(tmp_mode_guessing), key=tmp_mode_guessing.count)  # MAJORITY VOTE\n",
    "                    \n",
    "    return mode_guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impunt_missing_values(df):\n",
    "    # # list of lists (each list contains DataFrame's records missing values per column, \n",
    "    # where the column are either extracted from missing_numeric_values_columns\n",
    "    # and missing_categorical_values_columns arrays merged together)\n",
    "    missing_values_record_indeces = []  \n",
    "    \n",
    "    # checking each record's missing values \n",
    "    # N.B if a record has more than one missing value, it will show multiple times\n",
    "    # in the index process memorisation, but in different lists (different columns \n",
    "    # to impute)\n",
    "    for column_name in missing_values_columns:\n",
    "        column_attrition_index = df.columns.get_loc(\"Attrition\")\n",
    "        tmp_missing_idx = []\n",
    "        for i in range(0, len(df)):\n",
    "            column_index = df.columns.get_loc(column_name)\n",
    "            try:\n",
    "                df.iloc[i,column_index].split(\"_\")\n",
    "            except AttributeError:  # missing value (nan value)\n",
    "                # missing value replacement with correlated ARs\n",
    "                tmp_missing_idx.append(i)\n",
    "                    \n",
    "        missing_values_record_indeces.append(tmp_missing_idx)\n",
    "    \n",
    "    imputed_values = []\n",
    "    for i in range(0, len(missing_values_columns)):\n",
    "        record_indeces = missing_values_record_indeces[i]\n",
    "        missing_column_name = missing_values_columns[i]\n",
    "        missing_column_index = df.columns.get_loc(missing_column_name)\n",
    "        mode_guessing = AR_impunter(df, record_indeces, missing_column_name)\n",
    "        imputed_values.append(mode_guessing)\n",
    "        \n",
    "        not_impunted_records = 0\n",
    "        for j in range(0, len(record_indeces)):\n",
    "            if mode_guessing[j]:  # empty string == False\n",
    "                # df.iloc[record_indeces[j], missing_column_index] = mode_guessing[j]\n",
    "                pass\n",
    "            else:\n",
    "                 not_impunted_records += 1\n",
    "        print(\"column %s impunted records=%d\" % (missing_column_name, len(record_indeces) - not_impunted_records))\n",
    "        print(\"column %s NOT impunted records=%d\" % (missing_column_name, not_impunted_records))\n",
    "        \n",
    "    # return df  # imputation is made inside the function \n",
    "    return missing_values_record_indeces, imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impunted_train(df, indeces, column_index):\n",
    "    y_train = []\n",
    "    for idx in indeces:\n",
    "        y_train.append(df.iloc[idx, column_index])\n",
    "    return y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation_performance(missing_record_indeces, imputed_values, model_name, type_flag, cmap, color):\n",
    "    all_y_train = []\n",
    "    all_y_pred = []\n",
    "    for column_name, i in zip(missing_values_columns, range(0, len(missing_values_columns))):\n",
    "        if type_flag == \"train\":\n",
    "            column_index = df_converted.columns.get_loc(column_name)\n",
    "            y_train = get_impunted_train(df_converted, missing_record_indeces[i], column_index)\n",
    "        elif type_flag == \"test\":\n",
    "            column_index = df_ts_conv.columns.get_loc(column_name)\n",
    "            y_train = get_impunted_train(df_ts_conv, missing_record_indeces[i], column_index)\n",
    "        else:\n",
    "            print(\"Wrong type_flag %s\" % type_flag)\n",
    "            sys.exit(-1)\n",
    "        y_pred = imputed_values[i]\n",
    "        if len(y_train) != len(y_pred):\n",
    "            print(\"different len in impunted test for column_name %s\" % column_name)\n",
    "            sys.exit(-1)\n",
    "        all_y_train += y_train\n",
    "        all_y_pred += y_pred\n",
    "    print(classification_report(all_y_train, all_y_pred))\n",
    "    # plot_imputation_report(all_y_train, all_y_pred, cmap, model_name, list(set(all_y_train)))\n",
    "    # draw_normalized_confusion_matrises(model_name, all_y_train, all_y_pred, cmap)\n",
    "    # draw_roc_and_pr_curves(model_name, all_y_train, all_y_pred, type_flag, color, impunters_global_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train imputation </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column Age impunted records=0\n",
      "column Age NOT impunted records=136\n",
      "column YearsAtCompany impunted records=53\n",
      "column YearsAtCompany NOT impunted records=0\n",
      "column MonthlyIncome impunted records=167\n",
      "column MonthlyIncome NOT impunted records=0\n",
      "column TaxRate impunted records=0\n",
      "column TaxRate NOT impunted records=167\n",
      "column TrainingTimesLastYear impunted records=66\n",
      "column TrainingTimesLastYear NOT impunted records=109\n",
      "column BusinessTravel impunted records=79\n",
      "column BusinessTravel NOT impunted records=0\n",
      "column Gender impunted records=38\n",
      "column Gender NOT impunted records=0\n"
     ]
    }
   ],
   "source": [
    "missing_record_indeces, imputed_values = \\\n",
    "                            impunt_missing_values(df_not_impunted_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                                   0.00      0.00      0.00         0\n",
      "                       0_Age       0.00      0.00      0.00        33\n",
      "             0_MonthlyIncome       0.22      1.00      0.35        36\n",
      "                   0_TaxRate       0.00      0.00      0.00       167\n",
      "            0_YearsAtCompany       0.57      1.00      0.72        30\n",
      "                       1_Age       0.00      0.00      0.00        66\n",
      "             1_MonthlyIncome       0.00      0.00      0.00        45\n",
      "            1_YearsAtCompany       0.00      0.00      0.00        18\n",
      "                       2_Age       0.00      0.00      0.00        25\n",
      "             2_MonthlyIncome       0.00      0.00      0.00        45\n",
      "     2_TrainingTimesLastYear       1.00      0.38      0.55       175\n",
      "            2_YearsAtCompany       0.00      0.00      0.00         3\n",
      "                       3_Age       0.00      0.00      0.00        12\n",
      "             3_MonthlyIncome       0.00      0.00      0.00        41\n",
      "            3_YearsAtCompany       0.00      0.00      0.00         2\n",
      "                 Male_Gender       1.00      1.00      1.00        38\n",
      "Travel_Rarely_BusinessTravel       1.00      1.00      1.00        79\n",
      "\n",
      "                    accuracy                           0.31       815\n",
      "                   macro avg       0.22      0.26      0.21       815\n",
      "                weighted avg       0.39      0.31      0.30       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputation_performance(missing_record_indeces, imputed_values, \"AR impunter\", \"train\", plt.cm.Blues, \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test imputation</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column Age impunted records=0\n",
      "column Age NOT impunted records=28\n",
      "column YearsAtCompany impunted records=12\n",
      "column YearsAtCompany NOT impunted records=0\n",
      "column MonthlyIncome impunted records=51\n",
      "column MonthlyIncome NOT impunted records=0\n",
      "column TaxRate impunted records=0\n",
      "column TaxRate NOT impunted records=51\n",
      "column TrainingTimesLastYear impunted records=21\n",
      "column TrainingTimesLastYear NOT impunted records=28\n",
      "column BusinessTravel impunted records=17\n",
      "column BusinessTravel NOT impunted records=0\n",
      "column Gender impunted records=11\n",
      "column Gender NOT impunted records=0\n"
     ]
    }
   ],
   "source": [
    "missing_record_indeces, imputed_values = \\\n",
    "                            impunt_missing_values(df_ts_not_imp_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                                   0.00      0.00      0.00         0\n",
      "                       0_Age       0.00      0.00      0.00         6\n",
      "             0_MonthlyIncome       0.24      1.00      0.38        12\n",
      "                   0_TaxRate       0.00      0.00      0.00        51\n",
      "            0_YearsAtCompany       0.17      1.00      0.29         2\n",
      "                       1_Age       0.00      0.00      0.00        11\n",
      "             1_MonthlyIncome       0.00      0.00      0.00        16\n",
      "            1_YearsAtCompany       0.00      0.00      0.00         9\n",
      "                       2_Age       0.00      0.00      0.00        10\n",
      "             2_MonthlyIncome       0.00      0.00      0.00        12\n",
      "     2_TrainingTimesLastYear       1.00      0.43      0.60        49\n",
      "            2_YearsAtCompany       0.00      0.00      0.00         1\n",
      "                       3_Age       0.00      0.00      0.00         1\n",
      "             3_MonthlyIncome       0.00      0.00      0.00        11\n",
      "                 Male_Gender       1.00      1.00      1.00        11\n",
      "Travel_Rarely_BusinessTravel       1.00      1.00      1.00        17\n",
      "\n",
      "                    accuracy                           0.29       219\n",
      "                   macro avg       0.21      0.28      0.20       219\n",
      "                weighted avg       0.37      0.29      0.29       219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputation_performance(missing_record_indeces, imputed_values, \"AR impunter\", \"test\", plt.cm.Blues, \"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
