{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data mining project - 2020/21</b><br>\n",
    "<b>Author</b>: [Alexandra Bradan](https://github.com/alexandrabradan)<br>\n",
    "<b>Python version</b>: 3.x<br>\n",
    "<b>Last update: 07/01/2021<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# general libraries\n",
    "import sys\n",
    "import math\n",
    "import operator\n",
    "import itertools\n",
    "import pydotplus\n",
    "import collections\n",
    "import missingno as msno\n",
    "from pylab import MaxNLocator\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from IPython.display import Image\n",
    "\n",
    "# pandas libraries\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "# visualisation libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "# numpy libraries\n",
    "import numpy as np\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "from numpy import arange\n",
    "from numpy import unique\n",
    "from numpy import percentile\n",
    "\n",
    "# scipy libraries\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.experimental import enable_iterative_imputer  # explicitly require this experimental feature\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.pipeline import make_pipeline as imbmake_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score, recall_score, precision_score, classification_report, roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../../../data/\"\n",
    "plot_directory = \"../../../plots/DataUnderstanding/\"\n",
    "TR_file = data_directory + \"Train_HR_Employee_Attrition.csv\"\n",
    "TR_cleaned_file = data_directory + \"Numerical_Encoding_Train_HR_Employee_Attrition.csv\"\n",
    "TS_file = data_directory + \"Numerical_Encoding_Test_HR_Employee_Attrition.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv(TR_cleaned_file, sep=\",\") \n",
    "df_ts = pd.read_csv(TS_file, sep=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 883 entries, 0 to 882\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       883 non-null    int64  \n",
      " 1   Attrition                 883 non-null    int64  \n",
      " 2   BusinessTravel            883 non-null    int64  \n",
      " 3   DistanceFromHome          883 non-null    int64  \n",
      " 4   Education                 883 non-null    int64  \n",
      " 5   EnvironmentSatisfaction   883 non-null    int64  \n",
      " 6   Gender                    883 non-null    int64  \n",
      " 7   JobInvolvement            883 non-null    int64  \n",
      " 8   JobLevel                  883 non-null    int64  \n",
      " 9   JobRole                   883 non-null    int64  \n",
      " 10  JobSatisfaction           883 non-null    int64  \n",
      " 11  MonthlyIncome             883 non-null    int64  \n",
      " 12  NumCompaniesWorked        883 non-null    int64  \n",
      " 13  OverTime                  883 non-null    int64  \n",
      " 14  PercentSalaryHike         883 non-null    int64  \n",
      " 15  RelationshipSatisfaction  883 non-null    int64  \n",
      " 16  StockOptionLevel          883 non-null    int64  \n",
      " 17  TrainingTimesLastYear     883 non-null    int64  \n",
      " 18  WorkLifeBalance           883 non-null    int64  \n",
      " 19  YearsAtCompany            883 non-null    int64  \n",
      " 20  YearsInCurrentRole        883 non-null    int64  \n",
      " 21  MonthlyHours              883 non-null    float64\n",
      " 22  TaxRate                   883 non-null    float64\n",
      " 23  OverallSatisfaction       883 non-null    float64\n",
      "dtypes: float64(3), int64(21)\n",
      "memory usage: 165.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219 entries, 0 to 218\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       219 non-null    int64  \n",
      " 1   Attrition                 219 non-null    int64  \n",
      " 2   BusinessTravel            219 non-null    int64  \n",
      " 3   DistanceFromHome          219 non-null    int64  \n",
      " 4   Education                 219 non-null    int64  \n",
      " 5   EnvironmentSatisfaction   219 non-null    int64  \n",
      " 6   Gender                    219 non-null    int64  \n",
      " 7   JobInvolvement            219 non-null    int64  \n",
      " 8   JobLevel                  219 non-null    int64  \n",
      " 9   JobRole                   219 non-null    int64  \n",
      " 10  JobSatisfaction           219 non-null    int64  \n",
      " 11  MonthlyIncome             219 non-null    int64  \n",
      " 12  NumCompaniesWorked        219 non-null    int64  \n",
      " 13  OverTime                  219 non-null    int64  \n",
      " 14  PercentSalaryHike         219 non-null    int64  \n",
      " 15  RelationshipSatisfaction  219 non-null    int64  \n",
      " 16  StockOptionLevel          219 non-null    int64  \n",
      " 17  TrainingTimesLastYear     219 non-null    int64  \n",
      " 18  WorkLifeBalance           219 non-null    int64  \n",
      " 19  YearsAtCompany            219 non-null    int64  \n",
      " 20  YearsInCurrentRole        219 non-null    int64  \n",
      " 21  MonthlyHours              219 non-null    float64\n",
      " 22  TaxRate                   219 non-null    float64\n",
      " 23  OverallSatisfaction       219 non-null    float64\n",
      "dtypes: float64(3), int64(21)\n",
      "memory usage: 41.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_ts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(883, 24)\n",
      "(219, 24)\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.shape)\n",
    "print(df_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Discretisation approach </h2> \n",
    "Approaches to transform continuous variables into discrete ones. This process is also known as <b>binning</b>, with each bin being each interval. Discretization methods fall into 2 categories: \n",
    "\n",
    "- supervised: do not use any information, other than the variable distribution, to create the contiguous bins in which the values will be placed;\n",
    "- unsupervised: typically use target information in order to create bins or intervals.\n",
    "\n",
    "Since we are dealying with DT it is natural to use a **supervised discretisation method** with them:\n",
    "\n",
    "<u>Step 1</u>: First it trains a decision tree of limited depth (2, 3 or 4) using the variable we want to discretize to predict the target;\n",
    "\n",
    "<u>Step 2</u>: The original variable values are then replaced by the probability returned by the tree. The probability is the same for all the observations within a single bin, thus replacing by the probability is equivalent to grouping the observations within the cut-off decided by the decision tree.\n",
    "\n",
    "**Advantages** :\n",
    "- The probabilistic predictions returned decision tree are monotonically related to the target.\n",
    "- The new bins show decreased entropy, this is the observations within each bucket/bin are more similar to themselves than to those of other buckets/bins.\n",
    "- The tree finds the bins automatically.\n",
    "\n",
    "**Disadvantages**:\n",
    "- It may cause over-fitting\n",
    "- More importantly, some tuning of tree parameters might need to be done to obtain the optimal splits (e.g., depth, the minimum number of samples in one partition, the maximum number of partitions, and a minimum information gain). This it can be time-consuming.\n",
    "\n",
    "<u>Features to discretize</u>:\n",
    "- Age\n",
    "- DistanceFromHome\n",
    "- YearsAtCompany\n",
    "- YearsInCurrentRole\n",
    "- NumCompaniesWorked\n",
    "- MonthlyIncome\n",
    "- MonthlyHours\n",
    "\n",
    "- PercentSalaryHike\n",
    "- TaxRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training discretisation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_cleaned.copy()\n",
    "y_train = df_cleaned['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-353-f193d6d4a983>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-353-f193d6d4a983>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    X_train[curr_column] = pd.cut(X_train[curr_column], labels=labels, bins, include_lowest=True, right=False)\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "def discretize_based_on_histogram_distribution(curr_column, bins, labels):\n",
    "    print(\"%s max_train\" %curr_column, X_train[curr_column].max(), \"%s min_train\" % curr_column, X_train[curr_column].min())\n",
    "    print(\"%s max_test\" %curr_column, df_ts[curr_column].max(), \"%s min_test\" % curr_column, df_ts[curr_column].min())\n",
    "    print(pd.cut(X_train[curr_column], bins, labels=labels, include_lowest=True, right=False).unique())\n",
    "    X_train[curr_column] = pd.cut(X_train[curr_column], bins, include_lowest=True, right=False)\n",
    "    print(pd.cut(df_ts[curr_column], bins, labels=labels, include_lowest=True, right=False).unique())\n",
    "    df_ts[curr_column] = pd.cut(df_ts[curr_column], bins, labels=labels, include_lowest=True, right=False)\n",
    "    print(\"%s train_unique\" % curr_column, sorted(X_train[curr_column].unique()))\n",
    "    print(\"%s test_unique\" % curr_column, sorted(df_ts[curr_column].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Age </h6>\n",
    "Build a classification tree using the Age to predict Attrition in order to discretise the age variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(10, 71, 10))\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"Age\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>DistanceFromHome </h6>\n",
    "Build a classification tree using the variable to predict Attrition in order to discretise it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0, 31, 5))\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"DistanceFromHome\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> YearsAtCompany </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_indexes = df_ts.index[df_ts[\"YearsAtCompany\"] > 20]\n",
    "df_ts.drop(list(to_drop_indexes), axis=0, inplace=True)\n",
    "df_ts.reset_index(drop=True, inplace=True)\n",
    "print(\"dropped rows = \", len(to_drop_indexes), sep=\"\\t\")\n",
    "\n",
    "df_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0, 26, 5), )\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"YearsAtCompany\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> YearsInCurrentRole </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_indexes = df_ts.index[df_ts[\"YearsInCurrentRole\"] > 16]\n",
    "df_ts.drop(list(to_drop_indexes), axis=0, inplace=True)\n",
    "df_ts.reset_index(drop=True, inplace=True)\n",
    "print(\"dropped rows = \", len(to_drop_indexes), sep=\"\\t\")\n",
    "\n",
    "df_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0, 21, 5))\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"YearsInCurrentRole\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> NumCompaniesWorked </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0, 11, 5))\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"NumCompaniesWorked\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumCompaniesWorked is a discretisation candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> MonthlyIncome </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0, 30000, 2500))\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"MonthlyIncome\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> MonthlyHours </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_indexes = df_ts.index[df_ts[\"MonthlyHours\"] > 590.9767441860465]\n",
    "df_ts.drop(list(to_drop_indexes), axis=0, inplace=True)\n",
    "df_ts.reset_index(drop=True, inplace=True)\n",
    "print(\"dropped rows = \", len(to_drop_indexes), sep=\"\\t\")\n",
    "\n",
    "df_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0, 601, 200))\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"MonthlyHours\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> PercentSalaryHike </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0, 31, 5))\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"PercentSalaryHike\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> TaxRate </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(np.linspace(0, 1, 11))\n",
    "print(\"bins\", bins)\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"TaxRate\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> OverallSatisfaction </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(np.linspace(0, 5, 11))\n",
    "print(\"bins\", bins)\n",
    "labels= list(range(1, len(bins)))\n",
    "discretize_based_on_histogram_distribution(\"OverallSatisfaction\", bins, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Discretize variables and save them on new file </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cleaned.shape)\n",
    "print(df_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_cleaned.copy()\n",
    "df2 = df_ts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(data_directory + \"Discretized_HISTOGRAM_Numerical_Encoding_Train_HR_Employee_Attrition.csv\", index=False, header=True)\n",
    "df2.to_csv(data_directory + \"Discretized_HISTOGRAM_Numerical_Encoding_Test_HR_Employee_Attrition.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discretized = pd.read_csv(data_directory + \"Discretized_HISTOGRAM_Numerical_Encoding_Train_HR_Employee_Attrition.csv\", sep=\",\") \n",
    "df_discretized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discretized = pd.read_csv(data_directory + \"Discretized_HISTOGRAM_Numerical_Encoding_Test_HR_Employee_Attrition.csv\", sep=\",\") \n",
    "df_discretized.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
