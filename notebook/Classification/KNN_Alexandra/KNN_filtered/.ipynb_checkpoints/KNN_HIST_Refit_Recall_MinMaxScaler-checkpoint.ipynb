{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data mining project - 2020/21</b><br>\n",
    "<b>Author</b>: [Alexandra Bradan](https://github.com/alexandrabradan)<br>\n",
    "<b>Python version</b>: 3.x<br>\n",
    "<b>Last update: 07/01/2021<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import sys\n",
    "import math\n",
    "import operator\n",
    "import itertools\n",
    "import collections\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from IPython.display import Image\n",
    "\n",
    "# pandas libraries\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "# visualisation libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy libraries\n",
    "import numpy as np\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "from numpy import arange\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from numpy import percentile\n",
    "\n",
    "# scipy libraries\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.experimental import enable_iterative_imputer  # explicitly require this experimental feature\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.pipeline import make_pipeline as imbmake_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score, recall_score, precision_score, classification_report, roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../../../data/\"\n",
    "plot_directory = \"../../../plots/DataUnderstanding/\"\n",
    "TR_cleaned_file = data_directory + \"Discretized_HISTOGRAM_One_Hot_Encoding_Train_HR_Employee_Attrition2.csv\"\n",
    "TS_file = data_directory + \"Discretized_HISTOGRAM_One_Hot_Encoding_Test_HR_Employee_Attrition2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv(TR_cleaned_file, sep=\",\") \n",
    "df_cleaned = df_cleaned.drop(['YearsInCurrentRole','JobRole_Manager_Sales',\n",
    "              'JobRole_Manager_Human_Resources', 'JobRole_Sales_Executive',\n",
    "              'JobRole_Human_Resources','YearsAtCompany', 'MonthlyIncome','MonthlyHours',\n",
    "              'Education','Gender','BusinessTravel_Non-Travel',\n",
    "              'PercentSalaryHike','BusinessTravel_Travel_Frequently',\n",
    "              'BusinessTravel_Travel_Rarely','TaxRate', 'JobRole_Healthcare_Representative'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.read_csv(TS_file , sep=\",\") \n",
    "df_ts = df_ts.drop(['YearsInCurrentRole','JobRole_Manager_Sales',\n",
    "              'JobRole_Manager_Human_Resources', 'JobRole_Sales_Executive',\n",
    "              'JobRole_Human_Resources','YearsAtCompany', 'MonthlyIncome','MonthlyHours',\n",
    "              'Education','Gender','BusinessTravel_Non-Travel',\n",
    "              'PercentSalaryHike','BusinessTravel_Travel_Frequently',\n",
    "              'BusinessTravel_Travel_Rarely','TaxRate', 'JobRole_Healthcare_Representative'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(883, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Split dataset in Training and Test set </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(883, 19)\n"
     ]
    }
   ],
   "source": [
    "y = df_cleaned['Attrition']\n",
    "df1 = df_cleaned.copy()\n",
    "X = df1.drop('Attrition', axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Class=0 : 730/883 (82.7%)\n",
      "> Class=1 : 153/883 (17.3%)\n"
     ]
    }
   ],
   "source": [
    "# summarize dataset\n",
    "classes = unique(y)\n",
    "total = len(y)\n",
    "for c in classes:\n",
    "    n_examples = len(y[y==c])\n",
    "    percent = n_examples / total * 100\n",
    "    print('> Class=%d : %d/%d (%.1f%%)' % (c, n_examples, total, percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Imbalanced target variable </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our training set is highly unbalanced with respect to the target attribute object of the classification (Attrition=Yes: 153 (17.33%), Attrition=No:730 (82.67%)), we try to solve this problem using three resampling techniques: \n",
    "\n",
    "- **StratifiedKFold**: split a dataset randomly, in such a way that maintains the same class distribution in each fold.\n",
    "- **oversampling**: duplicates examples from minority class;  ==> may lead to overfitting\n",
    "- **undersampling**: deletes or filters examples from the majority class.  ==> may lead to underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize, title, cmap):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    # plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Stratified 70-30 holdout </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_X_train, tmp_X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> MinMaxScaler </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(tmp_X_train)\n",
    "X_train = scaler.transform(tmp_X_train)\n",
    "X_test = scaler.transform(tmp_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 3  # StratifiedKFold splits\n",
    "no_skill = len(y[y==1]) / len(y)  # PR_curve random model AUC\n",
    "sampling_methods_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top, scoring, scorings):\n",
    "    configurations = {}\n",
    "    c_i = 0\n",
    "    for i in range(1, n_top + 1):\n",
    "        # retrieeve best i-th model's score index\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)  # returns array([score_index])\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean training score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_train_score'][candidate],\n",
    "                  results['std_train_score'][candidate]))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            configurations[c_i] = results['params'][candidate]\n",
    "            c_i += 1 \n",
    "    return configurations\n",
    "\n",
    "\n",
    "def report_multiple(results, n_top, scoring, scorings):\n",
    "    configurations = {}\n",
    "    c_i = 0\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_' + str(scoring)] == i)\n",
    "        for candidate in candidates:\n",
    "            \"\"\"print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean training score:\", end = '')\n",
    "            for s in scorings:\n",
    "                print( \"   \" + s + \": {0:.3f} (std: {1:.3f})\".format(\n",
    "                      results['mean_train_' + s][candidate],\n",
    "                      results['std_train_' + s][candidate]), end = '')\n",
    "            \n",
    "\n",
    "            print(\"Mean validation score:\", end = '')\n",
    "            for s in scorings:\n",
    "                print( \"   \" + s + \": {0:.3f} (std: {1:.3f})\".format(\n",
    "                      results['mean_test_' + s][candidate],\n",
    "                      results['std_test_' + s][candidate]), end = '')\n",
    "\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\"\"\"\n",
    "            configurations[c_i] = results['params'][candidate]\n",
    "            c_i += 1 \n",
    "    return configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_best_model_info(resampling_label, models_u, roc_auc_models_u_val, precision_recall_auc_models_u_val,\n",
    "                           best_model_index_u, best_ap_model_index_u, models_thresh, best_thresh, \n",
    "                           ap_best_thresh, scoring, refit):\n",
    "    # keep_track_of_best_model_info\n",
    "    sampling_methods_info[resampling_label] = {}\n",
    "    cnf = models_u[best_model_index_u]\n",
    "    sampling_methods_info[resampling_label][\"model_param\"] = {}\n",
    "    sampling_methods_info[resampling_label][\"model_param\"][\"n_neighbors\"] = cnf.n_neighbors\n",
    "    sampling_methods_info[resampling_label][\"model_param\"][\"weights\"] = cnf.weights\n",
    "    sampling_methods_info[resampling_label][\"model_param\"][\"p\"] = cnf.p\n",
    "    sampling_methods_info[resampling_label][\"roc_auc_best_model_index\"] = best_model_index_u\n",
    "    sampling_methods_info[resampling_label][\"roc_auc\"] = roc_auc_models_u_val\n",
    "    sampling_methods_info[resampling_label][\"ap_best_model_index\"] = best_ap_model_index_u\n",
    "    sampling_methods_info[resampling_label][\"ap\"] = precision_recall_auc_models_u_val\n",
    "    sampling_methods_info[resampling_label][\"model_threshold\"] = models_thresh\n",
    "    sampling_methods_info[resampling_label][\"roc_auc_threshold\"] = best_thresh\n",
    "    sampling_methods_info[resampling_label][\"pr_ap_threshold\"] = ap_best_thresh\n",
    "    sampling_methods_info[resampling_label][\"scoring\"] = scoring\n",
    "    sampling_methods_info[resampling_label][\"refit\"] = refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree_classifier_params(sampler, resampling_label):\n",
    "    param_list = {'n_neighbors': list(range(2, 51)),\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'p': [1, 2]\n",
    "                 }\n",
    "    new_params = {'kneighborsclassifier__' + key: param_list[key] for key in param_list}\n",
    "    return sampler, new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs, threshold):\n",
    "    # apply threshold to positive probabilities to create labels\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_thresholds(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    # predict probabilities\n",
    "    yhat = model.predict_proba(X_test)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    probs = yhat[:, 1]\n",
    "    # define thresholds\n",
    "    thresholds = arange(0, 1, 0.001)\n",
    "    # evaluate each threshold\n",
    "    scores = [f1_score(y_test, to_labels(probs, t)) for t in thresholds]\n",
    "    # get best threshold\n",
    "    ix = argmax(scores)\n",
    "    print( 'ModelThreshold=%.3f, F-measure=%.5f ' % (thresholds[ix], scores[ix]))\n",
    "    return thresholds[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_grid_search(sampler, resampling_label, scoring, refit):    \n",
    "\n",
    "    # declare K-Fold validation to use\n",
    "    # declare model to use\n",
    "    # initialize sampler and GridSearchCV's hyperparameters to tune\n",
    "    cv = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    model =  KNeighborsClassifier()  #KNN\n",
    "    sampler, new_params = get_decision_tree_classifier_params(sampler, resampling_label)\n",
    "    \n",
    "    # declare a imbalance Pipeline to use \n",
    "    # (I'm using imblearn.pipeline since it allows to performe both K-Fold (resampling only on TR's folds)\n",
    "    # and model's tuning, at same time)\n",
    "    if sampler != \"\":\n",
    "        imba_pipeline = imbmake_pipeline(sampler, model)\n",
    "    imba_pipeline = imbmake_pipeline(model)\n",
    "\n",
    "    # perform GridSearchCV (hyperparameters tuning)\n",
    "    grid_search = GridSearchCV(imba_pipeline, param_grid=new_params, cv=cv, scoring=scoring, \n",
    "                                 refit=refit, verbose=1, return_train_score=True)\n",
    "    # build inductive model on TR\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    results = grid_search.cv_results_\n",
    "    cnfs = report_multiple(results, n_top=3, scoring=refit, scorings=scoring)\n",
    "    \n",
    "    # train_models:\n",
    "    if sampler != \"\":\n",
    "        x_u_train_resampled, y_u_train_resampled = sampler.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        x_u_train_resampled, y_u_train_resampled = X_train, y_train\n",
    "        \n",
    "    models_u = []\n",
    "    y_pred_vals_u = []\n",
    "    y_pred_trains_u = []\n",
    "    hyper_ps = grid_search.cv_results_\n",
    "    model_index = 0\n",
    "    for cnf in cnfs.values():\n",
    "        n_neighbors = cnf['kneighborsclassifier__n_neighbors']\n",
    "        weights = cnf['kneighborsclassifier__weights']\n",
    "        p = cnf['kneighborsclassifier__p']\n",
    "        clf = KNeighborsClassifier(n_neighbors=n_neighbors, \n",
    "                                     weights=weights,\n",
    "                                     p=p)\n",
    "        clf = clf.fit(x_u_train_resampled, y_u_train_resampled)\n",
    "        models_u.append(clf)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_pred_tr = clf.predict(x_u_train_resampled)\n",
    "        y_pred_vals_u.append(y_pred)\n",
    "        y_pred_trains_u.append(y_pred_tr)\n",
    "\n",
    "\n",
    "    # test_models\n",
    "    roc_auc_models_u_val = []  # models' TS ROC_AUC \n",
    "    precision_recall_auc_models_u_val = []  # models' TS PRECISION_RECALL_AUC\n",
    "    for i in range(0, len(cnfs)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_u_train_resampled, y_pred_trains_u[i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_auc = roc_auc_score(y_u_train_resampled, y_pred_trains_u[i], average=\"weighted\")\n",
    "        print(\"model {}\".format(i))\n",
    "        print('Train Accuracy %s' % accuracy_score(y_u_train_resampled, y_pred_trains_u[i]))\n",
    "        print('Train Precision %s' % precision_score(y_u_train_resampled, y_pred_trains_u[i], average=\"weighted\"))\n",
    "        print('Train Recall %s' % recall_score(y_u_train_resampled, y_pred_trains_u[i], average=\"weighted\"))\n",
    "        print('Train F1-score %s' % f1_score(y_u_train_resampled, y_pred_trains_u[i], average=\"weighted\"))\n",
    "        print('Train F2-score %s' % fbeta_score(y_u_train_resampled, y_pred_trains_u[i], average=\"weighted\",\n",
    "                                               beta=2))\n",
    "        print(\"Train roc_auc: {}\".format(roc_auc))\n",
    "        cm = confusion_matrix(y_u_train_resampled, y_pred_trains_u[i])\n",
    "        plot_confusion_matrix(cm, models_u[i].classes_, False, \"TR's confusion matrix for model %d\" %\\\n",
    "                              (i), plt.cm.Blues)\n",
    "        plt.show()\n",
    "\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_vals_u[i], average=\"weighted\")\n",
    "        roc_auc_models_u_val.append(roc_auc)\n",
    "        print(\"Validation roc_auc: {}\".format(roc_auc))\n",
    "        \n",
    "        pr_ap = average_precision_score(y_test, y_pred_vals_u[i], average=\"weighted\")\n",
    "        precision_recall_auc_models_u_val.append(pr_ap)\n",
    "        print(\"Validation precision_recall_ap: {}\".format(pr_ap))\n",
    "        \n",
    "        print('\\nValidation Accuracy %s' % accuracy_score(y_test, y_pred_vals_u[i]))\n",
    "        print('Validation Precision %s' % precision_score(y_test, y_pred_vals_u[i], average=\"weighted\"))\n",
    "        print('Validation Recall %s' % recall_score(y_test, y_pred_vals_u[i], average=\"weighted\"))\n",
    "        print('Validation F1-score %s' % f1_score(y_test, y_pred_vals_u[i], average=\"weighted\"))\n",
    "        print('Validation F2-score %s' % fbeta_score(y_test, y_pred_vals_u[i], average=\"weighted\", beta=2))\n",
    "        print(classification_report(y_test, y_pred_vals_u[i]))\n",
    "        cm = confusion_matrix(y_test, y_pred_vals_u[i])\n",
    "        plot_confusion_matrix(cm, models_u[i].classes_, False, \"VS' confusion matrix for model %d\" %\\\n",
    "                              (i), plt.cm.Blues)\n",
    "        plt.show()\n",
    "        print('Parameters model %s and resampling_label=%s: n_neighbors=%s, weights=%s, p=%s\"' % \n",
    "              (i, resampling_label, models_u[i].n_neighbors, models_u[i].weights, models_u[i].p))\n",
    "    \n",
    "    # get_best_model_index based on Precision_Recall_AP\n",
    "    for i in range(0,len(cnfs)):\n",
    "        print(\"model {} - precision_recall_ap: {}\".format(i, precision_recall_auc_models_u_val[i]))\n",
    "    best_pr_ap = max(precision_recall_auc_models_u_val)\n",
    "    best_ap_model_index_u = precision_recall_auc_models_u_val.index(best_pr_ap)\n",
    "    print(\"\\nBEST MODEL INDEX = %d\" % best_ap_model_index_u)\n",
    "\n",
    "        \n",
    "    # get_best_model_index based on ROC_AUC\n",
    "    for i in range(0,len(cnfs)):\n",
    "        print(\"model {} - roc_auc: {}\".format(i, roc_auc_models_u_val[i]))\n",
    "    best_roc_auc = max(roc_auc_models_u_val)\n",
    "    best_model_index_u = roc_auc_models_u_val.index(best_roc_auc)\n",
    "    print(\"\\nBEST MODEL INDEX = %d\" % best_model_index_u)\n",
    "    \n",
    "    models_thresh = get_model_thresholds(models_u[best_model_index_u])\n",
    "        \n",
    "    # draw_best_model_precision_recall_curve\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    precision, recall, ap_thresholds = precision_recall_curve(y_test, y_pred_vals_u[best_model_index_u])\n",
    "    # convert to f-measure\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f-measure\n",
    "    ix = argmax(fscore)\n",
    "    print( ' Best Threshold=%f, F-measure=%.3f ' % (ap_thresholds[ix], fscore[ix]))\n",
    "    ap_best_thresh = ap_thresholds[ix]\n",
    "    plt.plot(precision, recall, label='PR curve (AP=%0.4f)' %\\\n",
    "             (precision_recall_auc_models_u_val[best_model_index_u]))\n",
    "        \n",
    "    # calculate the no skill line as the proportion of the positive class\n",
    "    # plot the no skill precision-recall curve\n",
    "    plt.plot([0, 1], [no_skill, no_skill], 'k--', color=\"red\", label='Random model') \n",
    "    plt.xlim([0.0, 1])\n",
    "    plt.ylim([0.0, 1])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision') \n",
    "    plt.tick_params(axis='both', which='major')\n",
    "    plt.legend(loc=\"upper right\", fontsize=14, frameon=False)\n",
    "    plt.title(\"Model %d's PR AP(average precision)\" % best_model_index_u)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # draw_best_model_roc_auc\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_vals_u[best_model_index_u])\n",
    "    # Youdenâ€™s J statistic \n",
    "    J = tpr - fpr\n",
    "    # locate best threshold's index\n",
    "    ix = argmax(J)\n",
    "    best_thresh = thresholds[ix]\n",
    "    print( ' Best Threshold=%f ' % (best_thresh))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (AUC=%0.4f)' % (roc_auc_models_u_val[best_model_index_u]))\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], 'k--', color=\"red\", label='Random model') \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate') \n",
    "    plt.tick_params(axis='both', which='major')\n",
    "    plt.legend(loc=\"lower right\", fontsize=14, frameon=False)\n",
    "    plt.title(\"Model %d's ROC AUC\" % best_model_index_u)\n",
    "    plt.show()\n",
    "    \n",
    "    # keap track of best model's hyperparameters\n",
    "    update_best_model_info(resampling_label, models_u, roc_auc_models_u_val, precision_recall_auc_models_u_val,\\\n",
    "                          best_model_index_u, best_ap_model_index_u,  models_thresh, best_thresh, \\\n",
    "                          ap_best_thresh, scoring, refit)\n",
    "    \n",
    "    return models_u, roc_auc_models_u_val, precision_recall_auc_models_u_val, best_model_index_u,\\\n",
    "                                                                                    best_ap_model_index_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Plain TR</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_base = [\"recall\"]\n",
    "scoring_pool = [\"f1\", \"roc_auc\", \"precision\", \"f1_weighted\", \"average_precision\", \"roc_auc_ovo_weighted\"] \n",
    "refit_pool = [\"recall\", \"f1\", \"roc_auc\", \"f1_weighted\", \"average_precision\", \"roc_auc_ovo_weighted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_sets = set()\n",
    "for s in scoring_pool:\n",
    "    # scoring = scoring_base + list(powerset(scoring_pool))\n",
    "    tmp_list = list(powerset(scoring_pool))\n",
    "    max_set_size = len(scoring_pool)\n",
    "    for tmp_tuple in tmp_list:\n",
    "        tmp_tuple += (scoring_base[0],) \n",
    "        scoring_sets.add(tmp_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring=['average_precision', 'roc_auc_ovo_weighted', 'recall']refit=recall\n",
      "Fitting 3 folds for each of 196 candidates, totalling 588 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x7f19aa425d30 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alexandra/.local/lib/python3.6/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/home/alexandra/.local/lib/python3.6/site-packages/joblib/parallel.py\", line 359, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/home/alexandra/.local/lib/python3.6/site-packages/joblib/parallel.py\", line 792, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/home/alexandra/.local/lib/python3.6/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/alexandra/.local/lib/python3.6/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/alexandra/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"/home/alexandra/.local/lib/python3.6/site-packages/joblib/externals/loky/reusable_executor.py\", line 178, in submit\n",
      "    fn, *args, **kwargs)\n",
      "  File \"/home/alexandra/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
      "\n",
      "The exit codes of the workers are {EXIT(1), EXIT(1), EXIT(1)}\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1), EXIT(1), EXIT(1)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1467baeadfd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampling_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodels_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_models_u_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_recall_auc_models_u_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_index_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_ap_model_index_u\u001b[0m  \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                         \u001b[0mmy_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresampling_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-efe4493d2ea8>\u001b[0m in \u001b[0;36mmy_grid_search\u001b[0;34m(sampler, resampling_label, scoring, refit)\u001b[0m\n\u001b[1;32m     19\u001b[0m                                  refit=refit, n_jobs=-1, verbose=1, return_train_score=True)\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# build inductive model on TR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcnfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreport_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 178\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 raise ShutdownExecutorError(\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1), EXIT(1), EXIT(1)}"
     ]
    }
   ],
   "source": [
    "for scoring in scoring_sets:\n",
    "    scoring = list(scoring) \n",
    "    for refit in refit_pool:\n",
    "        resampling_label = \"scoring=\" + str(scoring) + \"refit=\" + str(refit)\n",
    "        print(resampling_label)\n",
    "        models_u, roc_auc_models_u_val, precision_recall_auc_models_u_val, best_model_index_u, best_ap_model_index_u  = \\\n",
    "                                                        my_grid_search(\"\", resampling_label, scoring, \"recall\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_roc_auc_key = \"\"\n",
    "max_roc_auc_mode_index = -1\n",
    "max_roc_auc_value = -1\n",
    "\n",
    "max_ap_key = \"\"\n",
    "max_ap_model_index = -1\n",
    "max_ap = -1\n",
    "for key, value, in sampling_methods_info.items():\n",
    "    roc_auc_best_model_index = sampling_methods_info[key][\"roc_auc_best_model_index\"]\n",
    "    if sampling_methods_info[key][\"roc_auc\"][roc_auc_best_model_index] >= max_roc_auc_value:\n",
    "        max_roc_auc_value = sampling_methods_info[key][\"roc_auc\"][roc_auc_best_model_index]\n",
    "        max_roc_auc_mode_index = roc_auc_best_model_index\n",
    "        max_roc_auc_key = key\n",
    "        \n",
    "    ap_best_model_index = sampling_methods_info[key][\"ap_best_model_index\"]\n",
    "    if sampling_methods_info[key][\"ap\"][ap_best_model_index] >= max_ap:\n",
    "        max_ap = sampling_methods_info[key][\"ap\"][ap_best_model_index]\n",
    "        max_ap_model_index = ap_best_model_index\n",
    "        max_ap_key = key\n",
    "        \n",
    "print(\"max_roc_auc_key\", max_roc_auc_key)\n",
    "print(\"max_roc_auc_mode_index\", max_roc_auc_mode_index)\n",
    "print(\"max_roc_auc\", max_roc_auc_value)\n",
    "print()\n",
    "print(\"max_ap_model_index\", max_ap_model_index)\n",
    "print(\"max_ap_key\", max_ap_key)\n",
    "print(\"max_ap\", max_ap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
